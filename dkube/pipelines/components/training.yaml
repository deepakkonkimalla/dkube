name: dkube-training
description: |
    Component which can be used to do training for deep learning models on Dkube platform.
    Dkube training offers,
    * Advanced options for distributed training, gpu managment & pooling.
    * Support Hyper parameter tuning.
    * MPI operator support for Horovod like training programs.
    * Ability to orchestrate and run custom training containers, prebuilt dkube datascience containers can also be used.
    * Renders nice Dashboard for training metrics and utilization graphs for GPU, CPU, Memory.
    * Support for early stopping if program is not converging - User can abort the Job and resume from previous point in training.
    * Tags to group related training jobs.
metadata:
  annotations: {platform: 'Dkube'}
  labels: {platform: 'Dkube', wfid: '{{workflow.uid}}', runid: '{{pod.name}}', stage: 'training'}
inputs:
  - {name:user,             type: String,   optional: false,
     description: 'Required. Logged in dkube user.'}

  - {name: auth_token,      type: String,   optional: false,
     description: 'Required. Dkube authentication token.'}

  - {name: framework,       type:String,    optional: false,
     description: 'Required. ML/DL framework to be used for training. Supported values tensorflow/custom.'}

  - {name: container,       type: Dict,     optional: false,
     description: 'Required. Container to use for training. Format: {"image":<url>, "username":<>, "password":<>}'}

  - {name: script,          type: String,   optional: true,
     description: 'Optional. Startup script to run inside container. If not passed expected is that container has entrypoint'}

  - {name: envs,            type: Dict,     optional: true,     default: '{}',
    description: 'Optional. Environments for training program. Format: {<key>:<val>,}.
                  Env var name inside container will be <key>=<val>'}

  - {name: program,         type: String,   optional: true,     default: '',
     description: 'Optional. Program imported in Dkube to be run inside container. If not specified container should have entrypoint.'}

  - {name: datasets,        type: List,     optional: true,     default: '[]',
     description: 'Optional. List of input datasets required for training. These datasets must be created in Dkube.'}

  - {name: models,          type: List,     optional: true,     default: '[]',
     description: 'Optional. List of pretrained models required for training. These models must be created in Dkube.'}

  - {name: ngpus,           type: Integer,  optional: true,     default: 0,
     description: 'Optional. Number of gpus the training program should use.'}

  - {name: distributeopts,  type: Dict,     optional: true,     default: '{}',
     description: 'Optional. Information about the distributed training.
                   Format: {"workers":<#training workers>, "ps":<#parameter servers>, "strategy":<one of the option below>}
                   Distribution strategy can be - DEFAULT/AUTO
                   TENSORFLOW strategy will be supported in future - @https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy.
                   Check the definitions and explanation @https://github.com/oneconvergence/dkube/tree/master/dkube/pipelines'}

  - {name: config,          type: String,   optional: true,      default: '',
    description: 'Optional. Configuration for training job. Supports inline data.
                  Future inputs :
                      <ks://<configmap-name>> -> k8s configmap name'}

  - {name: tuning,          type: String,   optional: true,     default: '',
     description: 'Optional. Hyperparameter tuning information. Supports inline data. Must be a json formatted string.
                   Future inputs :
                       <ks://<configmap-name>> -> k8s configmap name'}

  - {name: accessurl,       type: String,   optional: true,     default: '',
     description: 'Optional. URL at which dkube is accessible. Format: https://{ip}:{port}
                   Copy paste from the browser of this window. Required for cloud deployments.'}

outputs:
  - {name: rundetails,      description: 'Details of the dkube run'}
  - {name: artifact,        description: 'Identifier in Dkube storage where artifacts of training are stored.'}

implementation:
  container:
    image: ocdr/dkubepl:py
    command: ['dkubepl']
    args: [
      training, 
      --user, {inputValue: user},
      --accessurl, {inputValue: accessurl},
      --token, {inputValue: auth_token},
      --container, {inputValue: container},
      --script, {inputValue: script},
      --envs, {inputValue, envs},
      --program, {inputValue: program},
      --datasets, {inputValue: datasets},
      --models, {inputValue: models},
      --ngpus, {inputValue: ngpus},
      --distributeopts, {inputValue: distributeops},
      --config, {inputValue: config},
      --tuning, {inputValue: tuning},
      --runid, '{{pod.name}}'
    ]
    fileOutputs:
      rundetails:   /tmp/rundetails
      artifact:     /tmp/artifact
